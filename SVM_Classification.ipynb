{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#reference that helped with this:\n",
    "#https://stackabuse.com/implementing-lda-in-python-with-scikit-learn/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = pd.read_pickle(\"Cleaned_data.pkl\")\n",
    "del clean['key_name']\n",
    "del clean['mode_name']\n",
    "del clean['key_mode']\n",
    "del clean['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted  = clean.columns[1:13] #remove track name and labels\n",
    "#separate into features/labels\n",
    "features = clean[wanted]\n",
    "labels = clean['is_hit']\n",
    "#split data 70-30 training/testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state= 420)  \n",
    "#standardize the data\n",
    "std = StandardScaler()  \n",
    "X_train = std.fit_transform(X_train)  \n",
    "X_test = std.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88753991771915186"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run linear SVM 10 times with different C to find out the best one\n",
    "def runSVM(c):\n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    svm.predict(X_test)\n",
    "    return(svm.score(X_test, y_test))\n",
    "svm = LinearSVC()\n",
    "par = {'C':[1, 2, 5, 10, 20, 50]}\n",
    "gs = GridSearchCV(svm, par, return_train_score = True)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_params_)\n",
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88682285023830298"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runSVM(c=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM achieves 88.7% testing accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83540310129556283"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now try with polynomial features \n",
    "poly = PolynomialFeatures(degree = 3, include_bias = False)\n",
    "poly_feat = poly.fit_transform(features)\n",
    "#resplit into testing and training\n",
    "X_trainP, X_testP, y_trainP, y_testP = train_test_split(poly_feat, labels, test_size=0.3, random_state= 420)  \n",
    "#redo LinearSVM\n",
    "svm = LinearSVC(C=1) #kept C = 2 from LinearSVC above\n",
    "svm.fit(X_trainP, y_trainP)\n",
    "poly_preds = svm.predict(X_testP)\n",
    "svm.score(X_testP, y_testP) #accuracy went down a good amount, so polynomial features aren't efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try SGD since it has different params than linear svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0001}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88753991771915186"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use GridSearchCV() to optimize parameters for SGDClassifier\n",
    "sgd = SGDClassifier(max_iter =  5, tol = None)\n",
    "par = {'loss':('hinge', 'huber', 'modified_huber', 'log', 'epsilon_insensitive', 'squared_epsilon_insensitive'), 'alpha':[0.0001, 0.001], 'penalty':['l2', 'l1', 'elasticnet']}\n",
    "gs = GridSearchCV(sgd, par, return_train_score = True)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_params_)\n",
    "gs.best_score_\n",
    "#gs.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88682285023830298"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run SGD with best parameters\n",
    "sgd_best = SGDClassifier(loss = 'hinge', penalty = 'l1', alpha = 0.0001, max_iter = 10000)\n",
    "sgd_best.fit(X_train, y_train)\n",
    "sgdPreds = sgd_best.predict(X_test)\n",
    "sgd_best.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we get basically the same testing accuracy as before, so we can assume 88.7% accuracy is pretty much as accurate as we can get. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear svm AUC:  0.5\n",
      "Polynomial svm AUC:  0.512144320044\n",
      "SGD svm AUC:  0.5\n"
     ]
    }
   ],
   "source": [
    "#try seeing auc scores\n",
    "svm = LinearSVC(C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "preds = svm.predict(X_test)\n",
    "print(\"Linear svm AUC: \", roc_auc_score(y_test, preds))\n",
    "print(\"Polynomial svm AUC: \", roc_auc_score(y_testP, poly_preds)) #polynomial performs slightly better than linear svm\n",
    "print(\"SGD svm AUC: \", roc_auc_score(y_test, sgdPreds)) #no improvement for sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see here that for both Linear SVMs and SGD the AUC is 0.5, which is the same as a constant classifier. Polynomial performs slightly higher with 0.512443, but that is likely an insignificant improvement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now I will try to do some feature selection and rerun the models to see if AUC will change\n",
    "## In particular, I'll remove the 'energy', 'mode', 'key', 'instrumentalness', 'explicit', 'liveness', 'valence' and 'acousticness' variables since I suspect they are redundant features (since they are highly correlated with others). Mode and key in particular I think are actually more like categorical variables, so I'll see if  taking them out helps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>danceability</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.030722</td>\n",
       "      <td>-0.017644</td>\n",
       "      <td>0.110433</td>\n",
       "      <td>0.031025</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>-0.237438</td>\n",
       "      <td>-0.110361</td>\n",
       "      <td>-0.167252</td>\n",
       "      <td>0.209298</td>\n",
       "      <td>0.091941</td>\n",
       "      <td>0.145178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy</th>\n",
       "      <td>-0.030722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>0.705914</td>\n",
       "      <td>-0.021637</td>\n",
       "      <td>-0.053409</td>\n",
       "      <td>-0.410767</td>\n",
       "      <td>-0.121164</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.295124</td>\n",
       "      <td>0.096810</td>\n",
       "      <td>0.031145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <td>-0.017644</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002041</td>\n",
       "      <td>-0.226802</td>\n",
       "      <td>0.014789</td>\n",
       "      <td>0.033314</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.063116</td>\n",
       "      <td>-0.009217</td>\n",
       "      <td>-0.011886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loudness</th>\n",
       "      <td>0.110433</td>\n",
       "      <td>0.705914</td>\n",
       "      <td>-0.002041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007293</td>\n",
       "      <td>-0.254723</td>\n",
       "      <td>-0.401880</td>\n",
       "      <td>-0.208576</td>\n",
       "      <td>-0.034309</td>\n",
       "      <td>0.129657</td>\n",
       "      <td>0.118785</td>\n",
       "      <td>-0.026936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mode</th>\n",
       "      <td>0.031025</td>\n",
       "      <td>-0.021637</td>\n",
       "      <td>-0.226802</td>\n",
       "      <td>-0.007293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022706</td>\n",
       "      <td>-0.020437</td>\n",
       "      <td>-0.005078</td>\n",
       "      <td>0.021629</td>\n",
       "      <td>-0.036302</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>0.014558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speechiness</th>\n",
       "      <td>0.017000</td>\n",
       "      <td>-0.053409</td>\n",
       "      <td>0.014789</td>\n",
       "      <td>-0.254723</td>\n",
       "      <td>0.022706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.163634</td>\n",
       "      <td>-0.110668</td>\n",
       "      <td>0.195499</td>\n",
       "      <td>0.176812</td>\n",
       "      <td>-0.011507</td>\n",
       "      <td>0.224991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acousticness</th>\n",
       "      <td>-0.237438</td>\n",
       "      <td>-0.410767</td>\n",
       "      <td>0.033314</td>\n",
       "      <td>-0.401880</td>\n",
       "      <td>-0.020437</td>\n",
       "      <td>0.163634</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100265</td>\n",
       "      <td>0.050411</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>-0.159633</td>\n",
       "      <td>-0.095824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrumentalness</th>\n",
       "      <td>-0.110361</td>\n",
       "      <td>-0.121164</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>-0.208576</td>\n",
       "      <td>-0.005078</td>\n",
       "      <td>-0.110668</td>\n",
       "      <td>0.100265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.030919</td>\n",
       "      <td>-0.099386</td>\n",
       "      <td>-0.003108</td>\n",
       "      <td>-0.128906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liveness</th>\n",
       "      <td>-0.167252</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>-0.034309</td>\n",
       "      <td>0.021629</td>\n",
       "      <td>0.195499</td>\n",
       "      <td>0.050411</td>\n",
       "      <td>-0.030919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080366</td>\n",
       "      <td>-0.037132</td>\n",
       "      <td>0.073838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valence</th>\n",
       "      <td>0.209298</td>\n",
       "      <td>0.295124</td>\n",
       "      <td>0.063116</td>\n",
       "      <td>0.129657</td>\n",
       "      <td>-0.036302</td>\n",
       "      <td>0.176812</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>-0.099386</td>\n",
       "      <td>0.080366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020091</td>\n",
       "      <td>0.016457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempo</th>\n",
       "      <td>0.091941</td>\n",
       "      <td>0.096810</td>\n",
       "      <td>-0.009217</td>\n",
       "      <td>0.118785</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>-0.011507</td>\n",
       "      <td>-0.159633</td>\n",
       "      <td>-0.003108</td>\n",
       "      <td>-0.037132</td>\n",
       "      <td>0.020091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explicit</th>\n",
       "      <td>0.145178</td>\n",
       "      <td>0.031145</td>\n",
       "      <td>-0.011886</td>\n",
       "      <td>-0.026936</td>\n",
       "      <td>0.014558</td>\n",
       "      <td>0.224991</td>\n",
       "      <td>-0.095824</td>\n",
       "      <td>-0.128906</td>\n",
       "      <td>0.073838</td>\n",
       "      <td>0.016457</td>\n",
       "      <td>0.045938</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  danceability    energy       key  loudness      mode  \\\n",
       "danceability          1.000000 -0.030722 -0.017644  0.110433  0.031025   \n",
       "energy               -0.030722  1.000000  0.025556  0.705914 -0.021637   \n",
       "key                  -0.017644  0.025556  1.000000 -0.002041 -0.226802   \n",
       "loudness              0.110433  0.705914 -0.002041  1.000000 -0.007293   \n",
       "mode                  0.031025 -0.021637 -0.226802 -0.007293  1.000000   \n",
       "speechiness           0.017000 -0.053409  0.014789 -0.254723  0.022706   \n",
       "acousticness         -0.237438 -0.410767  0.033314 -0.401880 -0.020437   \n",
       "instrumentalness     -0.110361 -0.121164  0.000125 -0.208576 -0.005078   \n",
       "liveness             -0.167252  0.129310  0.002648 -0.034309  0.021629   \n",
       "valence               0.209298  0.295124  0.063116  0.129657 -0.036302   \n",
       "tempo                 0.091941  0.096810 -0.009217  0.118785  0.004089   \n",
       "explicit              0.145178  0.031145 -0.011886 -0.026936  0.014558   \n",
       "\n",
       "                  speechiness  acousticness  instrumentalness  liveness  \\\n",
       "danceability         0.017000     -0.237438         -0.110361 -0.167252   \n",
       "energy              -0.053409     -0.410767         -0.121164  0.129310   \n",
       "key                  0.014789      0.033314          0.000125  0.002648   \n",
       "loudness            -0.254723     -0.401880         -0.208576 -0.034309   \n",
       "mode                 0.022706     -0.020437         -0.005078  0.021629   \n",
       "speechiness          1.000000      0.163634         -0.110668  0.195499   \n",
       "acousticness         0.163634      1.000000          0.100265  0.050411   \n",
       "instrumentalness    -0.110668      0.100265          1.000000 -0.030919   \n",
       "liveness             0.195499      0.050411         -0.030919  1.000000   \n",
       "valence              0.176812      0.004966         -0.099386  0.080366   \n",
       "tempo               -0.011507     -0.159633         -0.003108 -0.037132   \n",
       "explicit             0.224991     -0.095824         -0.128906  0.073838   \n",
       "\n",
       "                   valence     tempo  explicit  \n",
       "danceability      0.209298  0.091941  0.145178  \n",
       "energy            0.295124  0.096810  0.031145  \n",
       "key               0.063116 -0.009217 -0.011886  \n",
       "loudness          0.129657  0.118785 -0.026936  \n",
       "mode             -0.036302  0.004089  0.014558  \n",
       "speechiness       0.176812 -0.011507  0.224991  \n",
       "acousticness      0.004966 -0.159633 -0.095824  \n",
       "instrumentalness -0.099386 -0.003108 -0.128906  \n",
       "liveness          0.080366 -0.037132  0.073838  \n",
       "valence           1.000000  0.020091  0.016457  \n",
       "tempo             0.020091  1.000000  0.045938  \n",
       "explicit          0.016457  0.045938  1.000000  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM:  0.5\n",
      "Polynomial svm AUC:  0.521181169975\n",
      "SGD svm AUC:  0.5\n"
     ]
    }
   ],
   "source": [
    "#drop seemingly redundant features\n",
    "new_features = features.drop(['energy', 'mode', 'key', 'instrumentalness', 'explicit', 'liveness', 'valence', 'acousticness'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_features, labels, test_size=0.3, random_state= 420)  \n",
    "#standardize the data\n",
    "std = StandardScaler()  \n",
    "X_train = std.fit_transform(X_train)  \n",
    "X_test = std.transform(X_test) \n",
    "#Do LinearSVC again\n",
    "svm = LinearSVC(C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "new_preds_lin = svm.predict(X_test)\n",
    "print(\"Linear SVM: \", roc_auc_score(y_test, new_preds_lin)) #auc doesn't change from .5\n",
    "#polynomial features \n",
    "poly_feat = poly.fit_transform(features)\n",
    "X_trainP, X_testP, y_trainP, y_testP = train_test_split(poly_feat, labels, test_size=0.3, random_state= 420)  \n",
    "#redo LinearSVM\n",
    "svm_poly = LinearSVC(C=1) #kept C = 2 from LinearSVC above\n",
    "svm_poly.fit(X_trainP, y_trainP)\n",
    "poly_preds_new = svm_poly.predict(X_testP)\n",
    "print(\"Polynomial svm AUC: \",roc_auc_score(y_testP, poly_preds_new)) #polynomial performs slightly better than linear svm\n",
    "sgd_best_new = SGDClassifier(loss = 'hinge', penalty = 'l1', alpha = 0.0001, max_iter = 10000)\n",
    "sgd_best_new.fit(X_train, y_train)\n",
    "sgdPreds_new = sgd_best_new.predict(X_test)\n",
    "print(\"SGD svm AUC: \", roc_auc_score(y_test, sgdPreds_new)) #no improvement for sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only polynomial svm's AUC benefited from dropping these variables. At this point, I believe that Support Vector Machine Classifiers are not suited for our problem. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
