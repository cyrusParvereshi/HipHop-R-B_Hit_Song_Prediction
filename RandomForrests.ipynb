{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is a Random Forrest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The building block of a random forrest is a **decision tree**. The idea is that we use a series of questions that give binary (True or False answers), with each question narrowing our possible values until we were confident enough to make a single prediction. Start at some node, ask a question and depending on the answer (True/False) we move down the tree. Decision trees learn the relationship between the data input and the outputs by using the best questions to make accuracte predictions. When given an observation to predict, the model makes a prediction based on the structure learned through training. The model essentially learns how to map features to some target (hit song or not). However, there is high variability with this model. A solution to this is using a random forest.\n",
    "\n",
    "As a supervised machine learning model, a **random forest** learns to map data (sound,pitch,danceability,etc.) to outputs (Hit song or not Hit song) during the training stage. The idea dea behind a random forest is that it is a combination of many decision trees, and the majority vote of the trees with be closer to the true true value. Here, each decision tree used a random subset of the features to form questions and only has access to a random set of the training data points, this results in a more robust prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Advantages and Disadvantages of a Random Forrest\n",
    "\n",
    "###### Advantages\n",
    "The advantages of a random forrest are not needing to normalize or scale the data, easy to measure the relative importance of a feature, and can handle categorical and numerical features. Random Forrest do not need to be normalized becuase convergence and numerical precision complications associated with other algorithms like linear regression are not relevant to random forrests. Due to the nature of this algorithm, the algorithm will not favor one feature over another if it is not normalized. Therefore, scaling our data would not be necessary to obtain more desirable results.\n",
    "\n",
    "###### Disadvantages\n",
    "The disadvantages of a random forrest are complexity, potential long time to execute (depending on the number of trees), and there is a sacrifice of interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>disc_number</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>is_hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.670</td>\n",
       "      <td>0.428</td>\n",
       "      <td>3</td>\n",
       "      <td>-10.161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.537000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.326</td>\n",
       "      <td>100.033</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>289596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.694</td>\n",
       "      <td>0.645</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.841</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>0.007210</td>\n",
       "      <td>0.0595</td>\n",
       "      <td>0.549</td>\n",
       "      <td>171.877</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>357581</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.641</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.191</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>0.593</td>\n",
       "      <td>99.998</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>232888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.638</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.358</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0407</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.201</td>\n",
       "      <td>93.031</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>215022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.685</td>\n",
       "      <td>0.509</td>\n",
       "      <td>6</td>\n",
       "      <td>-8.606</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.212000</td>\n",
       "      <td>0.754000</td>\n",
       "      <td>0.0704</td>\n",
       "      <td>0.464</td>\n",
       "      <td>93.986</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>276063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.670   0.428    3   -10.161     0       0.0369      0.537000   \n",
       "1         0.694   0.645    1    -6.841     0       0.1970      0.012600   \n",
       "2         0.750   0.641    1    -4.191     1       0.0743      0.272000   \n",
       "3         0.638   0.845    0    -4.358     1       0.0407      0.000815   \n",
       "4         0.685   0.509    6    -8.606     0       0.1120      0.212000   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  time_signature  disc_number  \\\n",
       "0          0.000003    0.1180    0.326  100.033               4            1   \n",
       "1          0.007210    0.0595    0.549  171.877               4            1   \n",
       "2          0.000010    0.1080    0.593   99.998               4            1   \n",
       "3          0.000418    0.0503    0.201   93.031               4            1   \n",
       "4          0.754000    0.0704    0.464   93.986               4            1   \n",
       "\n",
       "   duration_ms  is_hit  \n",
       "0       289596       0  \n",
       "1       357581       0  \n",
       "2       232888       0  \n",
       "3       215022       0  \n",
       "4       276063       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "data = pd.read_pickle('merged_data.pkl') \n",
    "\n",
    "# identfiy numerical volumns\n",
    "columns = ['danceability','energy','key','loudness','mode',\n",
    " 'speechiness','acousticness','instrumentalness',\n",
    " 'liveness','valence','tempo','time_signature','disc_number','duration_ms','is_hit']\n",
    "\n",
    "df = data[columns] # get numerical columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider Training on select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
       "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
       "       'time_signature', 'disc_number', 'duration_ms', 'is_hit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-3349cffec4ec>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-3349cffec4ec>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    X = df[,:-1]\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "X = df.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Data into train test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Feature Scaling (Optional/not needed for Random Forrest)\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#sc = StandardScaler()  \n",
    "#X_train = sc.fit_transform(X_train)  \n",
    "#X_test = sc.transform(X_test)  \n",
    "\n",
    "# feature scaling is not important for random forrest models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Random Forrest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model creation\n",
    "rfc = RandomForestClassifier(n_estimators=25)\n",
    "rfc.fit(X_train,y_train)\n",
    "\n",
    "# predictions\n",
    "y_predict = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation\n",
    "rfc_cv_score = cross_val_score(rfc, X, y, cv=10, scoring=\"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Confusion Matrix ===\")\n",
    "# print(confusion_matrix(y_test, y_predict))\n",
    "x = pd.crosstab(y_test, y_predict, rownames=['Actual'], colnames=['Predicted'])\n",
    "print(x)\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_predict))\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix** : Tells us false positives and false negatives. <br>\n",
    "**Classification Report** : Tells us the accuracy of the classifier in classifying the data points in that particular class compared to all other classes <br>\n",
    "The **ROC curve** plots out the true positive rate versus the false positive rate at various thresholds.<br>\n",
    "The **roc_auc scoring** used in the cross-validation model shows the area under the ROC curve. <br>\n",
    "\n",
    "ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. We used 10 fold cross validation to compute the AUC for each fold. then we returned all AUC Scores for each fold respectively. We computed the mean of these as well. We are dealing with a binary classification problem and AUC is a good evaluation metric for these types of problems. <br> \n",
    "\n",
    "* 1 is an indication our model has perfect separability <br>\n",
    "* 0.5 is an indication our model has no separability <br>\n",
    "* 0 is an indication our model is worst and is recipricating the result<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(\"The accuracy rate is:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC of base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_predict)\n",
    "base_roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "base_roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps we can remove some unimportant features to improve the score of the model (AUC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = list(rfc.feature_importances_)\n",
    "feature_list = list(df.drop('is_hit', axis=1).columns)\n",
    "\n",
    "# Get numerical feature importances\"\"\n",
    "importances = list(rfc.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "items = [print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical', color = 'r', edgecolor = 'k', linewidth = 1.2)\n",
    "\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features sorted from most to least important\n",
    "sorted_importances = [importance[1] for importance in feature_importances]\n",
    "sorted_features = [importance[0] for importance in feature_importances]\n",
    "\n",
    "# Cumulative importances\n",
    "cumulative_importances = np.cumsum(sorted_importances)\n",
    "\n",
    "# Make a line graph\n",
    "plt.plot(x_values, cumulative_importances, 'g-')\n",
    "\n",
    "# Draw line at 95% of importance retained\n",
    "plt.hlines(y = 0.9, xmin=0, xmax=len(sorted_importances), color = 'r', linestyles = 'dashed')\n",
    "\n",
    "# Format x ticks and labels\n",
    "plt.xticks(x_values, sorted_features, rotation = 'vertical')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.xlabel('Variable'); plt.ylabel('Cumulative Importance'); plt.title('Cumulative Importances');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set an arbritrary threshold of 90% importance. Any additional feature that adds past this threshold is uncessary and will be considered an unimportant feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refit RandomForrest Model with important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the names of the most important features\n",
    "important_feature_names = [feature[0] for feature in feature_importances[0:9]]\n",
    "\n",
    "# Create training and testing sets with only the important features\n",
    "important_X = X[important_feature_names] # this removes unimportant features\n",
    "y = y # y remains the same\n",
    "\n",
    "# implementing train-test-split on important features\n",
    "X_train, X_test, y_train, y_test = train_test_split(important_X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "# random forest model creation\n",
    "rfc = RandomForestClassifier(n_estimators=25)\n",
    "rfc.fit(X_train,y_train)\n",
    "\n",
    "# predictions\n",
    "y_predict = rfc.predict(X_test)\n",
    "\n",
    "# cross-validation\n",
    "rfc_cv_score = cross_val_score(rfc, X, y, cv=10, scoring=\"roc_auc\")\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "# print(confusion_matrix(y_test, y_predict))\n",
    "x = pd.crosstab(y_test, y_predict, rownames=['Actual'], colnames=['Predicted'])\n",
    "print(x)\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_predict))\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(\"The accuracy rate is:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC of Model with Removed Unimportant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_predict)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc_of_important_features = roc_auc\n",
    "roc_auc_of_important_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps we can further fine-tune our model to achieve a better score through hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning To Further Improve Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will attempt to optimize the settings of the algorithm to see if it can increase the score of our model. Sci-kit has default parameters but this does not guarantee optimal performance. Since it is impossible to determine the optimal paramters ahead of time, tuning is done after everything else is done.\n",
    "\n",
    "The standard procedure for hyperparameter optimization accounts for overfitting through cross validation. We want to avoid overfitting -- when our model scores well on training data but does not score well on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Cross- Validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many methods to implement cross-validation. A common method used is K-fold cross validation. After splitting the data into training and test data, we can further split the data into K-folds. The model then is fit K times, where K-1 of the folds serves as the training data and the remaining folds serves as the test data. We then compute some value metric, such as AUC for binary classifcation, for each iteration of model training. Then we take the average of the value metric for each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search Cross Validation in Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learnâ€™s `RandomizedSearchCV` allows us to specify a grid of hyperparameter ranges, and randomly sample from the grid, performing K-Fold CV with each combination of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at parameters used by our current forest clasifier\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rfc.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will create a parameter grid in order to use `RandomSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators= [10,20,25,30]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [5,10,15,20]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each iteration, a random combination of these parameters will be selected, not all ocmbination will be tested but rather only a random sample of a wide range of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation: i.e. \"20 percent is used for testing\"\n",
    "# search across 25 different combinations, and use all available cores\n",
    "\n",
    "rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid,\n",
    "                                n_iter = 25, cv = 3, verbose=2, random_state=1, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rfc_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance vs. Time Trade-off**\n",
    "Increasing the number of iterations increases the number of combinations to try. By increasing the iterations and number of folds we can reduce the chances of overfitting, but the runtime will increase. Perhaps if time permits, we can increase these parameters to imrpove model perfomance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we identified the best parameters, we can see if it improves the score of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HyperParameter Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing train-test-split on important features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "# random forest model creation\n",
    "rfc = RandomForestClassifier(n_estimators=25,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',\n",
    "                             max_depth = None, bootstrap = False)\n",
    "rfc.fit(X_train,y_train)\n",
    "\n",
    "# predictions\n",
    "y_predict = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation\n",
    "rfc_cv_score = cross_val_score(rfc, X, y, cv=5, scoring=\"roc_auc\")\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "# print(confusion_matrix(y_test, y_predict))\n",
    "x = pd.crosstab(y_test, y_predict, rownames=['Actual'], colnames=['Predicted'])\n",
    "print(x)\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_predict))\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_predict)\n",
    "final_roc_auc= auc(false_positive_rate, true_positive_rate)\n",
    "final_roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning our hyperparameters we achieve an improved score of 73.6%. Although this is not an excellent score, it is fair and an improvement from our base model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of Scores of Each Model\n",
    "1) Model 1 - Base Model <br>\n",
    "2) Model 2 - Base Model + Extracting Important Features (Features)<br>\n",
    "3) Model 3 - Base Model + Extracting Important Features + Hyperparameter tuning (Best) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['Base','Features','Hyperparameter Tuning']\n",
    "y = [base_roc_auc,roc_auc_of_important_features,final_roc_auc]\n",
    "\n",
    "plt.bar(x, y, color = 'g', edgecolor = 'k', linewidth = 1.8)\n",
    "plt.xticks(x)\n",
    "plt.ylim(ymin = 0.60, ymax = .74)\n",
    "plt.xlabel('Model'); plt.ylabel('AUC Score'); plt.title('Model Score Comparison');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementing Random Forrest**\n",
    "* https://medium.com/@williamkoehrsen/random-forest-simple-explanation-377895a60d2d\n",
    "* https://towardsdatascience.com/improving-random-forest-in-python-part-1-893916666cd\n",
    "* https://medium.com/@hjhuney/implementing-a-random-forest-classification-model-in-python-583891c99652\n",
    "\n",
    "**what is a good AUC?**\n",
    "* http://gim.unmc.edu/dxtests/roc3.htm\n",
    "* https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it\n",
    "\n",
    "**measuring model**\n",
    "* AUC vs standard accuracy\n",
    "* https://datascience.stackexchange.com/questions/806/advantages-of-auc-vs-standard-accuracy\n",
    "\n",
    "**Hyperparameter Tuning**\n",
    "* https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "* https://medium.com/all-things-ai/in-depth-parameter-tuning-for-random-forest-d67bb7e920d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
