{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#reference that helped with this:\n",
    "#https://stackabuse.com/implementing-lda-in-python-with-scikit-learn/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = pd.read_pickle(\"Cleaned_data.pkl\")\n",
    "del clean['key_name']\n",
    "del clean['mode_name']\n",
    "del clean['key_mode']\n",
    "del clean['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted  = clean.columns[1:13] #remove track name and labels\n",
    "#separate into features/labels\n",
    "features = clean[wanted]\n",
    "labels = clean['is_hit']\n",
    "#split data 70-30 training/testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state= 420)  \n",
    "#standardize the data\n",
    "std = StandardScaler()  \n",
    "X_train = std.fit_transform(X_train)  \n",
    "X_test = std.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88753991771915186"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run linear SVM 10 times with different C to find out the best one\n",
    "def runSVM(c):\n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    svm.predict(X_test)\n",
    "    return(svm.score(X_test, y_test))\n",
    "svm = LinearSVC()\n",
    "par = {'C':[1, 2, 5, 10, 20, 50]}\n",
    "gs = GridSearchCV(svm, par, return_train_score = True)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_params_)\n",
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88682285023830298"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runSVM(c=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM achieves 88.7% testing accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83540310129556283"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now try with polynomial features \n",
    "poly = PolynomialFeatures(degree = 3, include_bias = False)\n",
    "poly_feat = poly.fit_transform(features)\n",
    "#resplit into testing and training\n",
    "X_trainP, X_testP, y_trainP, y_testP = train_test_split(poly_feat, labels, test_size=0.3, random_state= 420)  \n",
    "#redo LinearSVM\n",
    "svm = LinearSVC(C=1) #kept C = 2 from LinearSVC above\n",
    "svm.fit(X_trainP, y_trainP)\n",
    "poly_preds = svm.predict(X_testP)\n",
    "svm.score(X_testP, y_testP) #accuracy went down a good amount, so polynomial features aren't efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try SGD since it has different params than linear svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'loss': 'hinge', 'alpha': 0.0001}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88753991771915186"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use GridSearchCV() to optimize parameters for SGDClassifier\n",
    "sgd = SGDClassifier(max_iter =  5, tol = None)\n",
    "par = {'loss':('hinge', 'huber', 'modified_huber', 'log', 'epsilon_insensitive', 'squared_epsilon_insensitive'), 'alpha':[0.0001, 0.001], 'penalty':['l2', 'l1', 'elasticnet']}\n",
    "gs = GridSearchCV(sgd, par, return_train_score = True)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_params_)\n",
    "gs.best_score_\n",
    "#gs.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88682285023830298"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run SGD with best parameters\n",
    "sgd_best = SGDClassifier(loss = 'hinge', penalty = 'l1', alpha = 0.0001, max_iter = 10000)\n",
    "sgd_best.fit(X_train, y_train)\n",
    "sgdPreds = sgd_best.predict(X_test)\n",
    "sgd_best.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we get basically the same testing accuracy as before, so we can assume 88.7% accuracy is pretty much as accurate as we can get. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear svm AUC:  0.5\n",
      "Polynomial svm AUC:  0.512144320044\n",
      "SGD svm AUC:  0.5\n"
     ]
    }
   ],
   "source": [
    "#try seeing auc scores\n",
    "svm = LinearSVC(C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "preds = svm.predict(X_test)\n",
    "print(\"Linear svm AUC: \", roc_auc_score(y_test, preds))\n",
    "print(\"Polynomial svm AUC: \", roc_auc_score(y_testP, poly_preds)) #polynomial performs slightly better than linear svm\n",
    "print(\"SGD svm AUC: \", roc_auc_score(y_test, sgdPreds)) #no improvement for sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see here that for both Linear SVMs and SGD the AUC is 0.5, which is the same as a constant classifier. Polynomial performs slightly higher with 0.512443, but that is likely an insignificant improvement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now I will try to do some feature selection and rerun the models to see if AUC will change\n",
    "## In particular, I'll remove the 'energy', 'mode', 'key', 'instrumentalness', 'explicit', 'liveness', 'valence' and 'acousticness' variables since I suspect they are redundant features (since they are highly correlated with others). Mode and key in particular I think are actually more like categorical variables, so I'll see if  taking them out helps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>danceability</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.030722</td>\n",
       "      <td>-0.017644</td>\n",
       "      <td>0.110433</td>\n",
       "      <td>0.031025</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>-0.237438</td>\n",
       "      <td>-0.110361</td>\n",
       "      <td>-0.167252</td>\n",
       "      <td>0.209298</td>\n",
       "      <td>0.091941</td>\n",
       "      <td>0.145178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy</th>\n",
       "      <td>-0.030722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>0.705914</td>\n",
       "      <td>-0.021637</td>\n",
       "      <td>-0.053409</td>\n",
       "      <td>-0.410767</td>\n",
       "      <td>-0.121164</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.295124</td>\n",
       "      <td>0.096810</td>\n",
       "      <td>0.031145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <td>-0.017644</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002041</td>\n",
       "      <td>-0.226802</td>\n",
       "      <td>0.014789</td>\n",
       "      <td>0.033314</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.063116</td>\n",
       "      <td>-0.009217</td>\n",
       "      <td>-0.011886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loudness</th>\n",
       "      <td>0.110433</td>\n",
       "      <td>0.705914</td>\n",
       "      <td>-0.002041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007293</td>\n",
       "      <td>-0.254723</td>\n",
       "      <td>-0.401880</td>\n",
       "      <td>-0.208576</td>\n",
       "      <td>-0.034309</td>\n",
       "      <td>0.129657</td>\n",
       "      <td>0.118785</td>\n",
       "      <td>-0.026936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mode</th>\n",
       "      <td>0.031025</td>\n",
       "      <td>-0.021637</td>\n",
       "      <td>-0.226802</td>\n",
       "      <td>-0.007293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022706</td>\n",
       "      <td>-0.020437</td>\n",
       "      <td>-0.005078</td>\n",
       "      <td>0.021629</td>\n",
       "      <td>-0.036302</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>0.014558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speechiness</th>\n",
       "      <td>0.017000</td>\n",
       "      <td>-0.053409</td>\n",
       "      <td>0.014789</td>\n",
       "      <td>-0.254723</td>\n",
       "      <td>0.022706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.163634</td>\n",
       "      <td>-0.110668</td>\n",
       "      <td>0.195499</td>\n",
       "      <td>0.176812</td>\n",
       "      <td>-0.011507</td>\n",
       "      <td>0.224991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acousticness</th>\n",
       "      <td>-0.237438</td>\n",
       "      <td>-0.410767</td>\n",
       "      <td>0.033314</td>\n",
       "      <td>-0.401880</td>\n",
       "      <td>-0.020437</td>\n",
       "      <td>0.163634</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100265</td>\n",
       "      <td>0.050411</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>-0.159633</td>\n",
       "      <td>-0.095824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrumentalness</th>\n",
       "      <td>-0.110361</td>\n",
       "      <td>-0.121164</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>-0.208576</td>\n",
       "      <td>-0.005078</td>\n",
       "      <td>-0.110668</td>\n",
       "      <td>0.100265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.030919</td>\n",
       "      <td>-0.099386</td>\n",
       "      <td>-0.003108</td>\n",
       "      <td>-0.128906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liveness</th>\n",
       "      <td>-0.167252</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>-0.034309</td>\n",
       "      <td>0.021629</td>\n",
       "      <td>0.195499</td>\n",
       "      <td>0.050411</td>\n",
       "      <td>-0.030919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080366</td>\n",
       "      <td>-0.037132</td>\n",
       "      <td>0.073838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valence</th>\n",
       "      <td>0.209298</td>\n",
       "      <td>0.295124</td>\n",
       "      <td>0.063116</td>\n",
       "      <td>0.129657</td>\n",
       "      <td>-0.036302</td>\n",
       "      <td>0.176812</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>-0.099386</td>\n",
       "      <td>0.080366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020091</td>\n",
       "      <td>0.016457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempo</th>\n",
       "      <td>0.091941</td>\n",
       "      <td>0.096810</td>\n",
       "      <td>-0.009217</td>\n",
       "      <td>0.118785</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>-0.011507</td>\n",
       "      <td>-0.159633</td>\n",
       "      <td>-0.003108</td>\n",
       "      <td>-0.037132</td>\n",
       "      <td>0.020091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explicit</th>\n",
       "      <td>0.145178</td>\n",
       "      <td>0.031145</td>\n",
       "      <td>-0.011886</td>\n",
       "      <td>-0.026936</td>\n",
       "      <td>0.014558</td>\n",
       "      <td>0.224991</td>\n",
       "      <td>-0.095824</td>\n",
       "      <td>-0.128906</td>\n",
       "      <td>0.073838</td>\n",
       "      <td>0.016457</td>\n",
       "      <td>0.045938</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  danceability    energy       key  loudness      mode  \\\n",
       "danceability          1.000000 -0.030722 -0.017644  0.110433  0.031025   \n",
       "energy               -0.030722  1.000000  0.025556  0.705914 -0.021637   \n",
       "key                  -0.017644  0.025556  1.000000 -0.002041 -0.226802   \n",
       "loudness              0.110433  0.705914 -0.002041  1.000000 -0.007293   \n",
       "mode                  0.031025 -0.021637 -0.226802 -0.007293  1.000000   \n",
       "speechiness           0.017000 -0.053409  0.014789 -0.254723  0.022706   \n",
       "acousticness         -0.237438 -0.410767  0.033314 -0.401880 -0.020437   \n",
       "instrumentalness     -0.110361 -0.121164  0.000125 -0.208576 -0.005078   \n",
       "liveness             -0.167252  0.129310  0.002648 -0.034309  0.021629   \n",
       "valence               0.209298  0.295124  0.063116  0.129657 -0.036302   \n",
       "tempo                 0.091941  0.096810 -0.009217  0.118785  0.004089   \n",
       "explicit              0.145178  0.031145 -0.011886 -0.026936  0.014558   \n",
       "\n",
       "                  speechiness  acousticness  instrumentalness  liveness  \\\n",
       "danceability         0.017000     -0.237438         -0.110361 -0.167252   \n",
       "energy              -0.053409     -0.410767         -0.121164  0.129310   \n",
       "key                  0.014789      0.033314          0.000125  0.002648   \n",
       "loudness            -0.254723     -0.401880         -0.208576 -0.034309   \n",
       "mode                 0.022706     -0.020437         -0.005078  0.021629   \n",
       "speechiness          1.000000      0.163634         -0.110668  0.195499   \n",
       "acousticness         0.163634      1.000000          0.100265  0.050411   \n",
       "instrumentalness    -0.110668      0.100265          1.000000 -0.030919   \n",
       "liveness             0.195499      0.050411         -0.030919  1.000000   \n",
       "valence              0.176812      0.004966         -0.099386  0.080366   \n",
       "tempo               -0.011507     -0.159633         -0.003108 -0.037132   \n",
       "explicit             0.224991     -0.095824         -0.128906  0.073838   \n",
       "\n",
       "                   valence     tempo  explicit  \n",
       "danceability      0.209298  0.091941  0.145178  \n",
       "energy            0.295124  0.096810  0.031145  \n",
       "key               0.063116 -0.009217 -0.011886  \n",
       "loudness          0.129657  0.118785 -0.026936  \n",
       "mode             -0.036302  0.004089  0.014558  \n",
       "speechiness       0.176812 -0.011507  0.224991  \n",
       "acousticness      0.004966 -0.159633 -0.095824  \n",
       "instrumentalness -0.099386 -0.003108 -0.128906  \n",
       "liveness          0.080366 -0.037132  0.073838  \n",
       "valence           1.000000  0.020091  0.016457  \n",
       "tempo             0.020091  1.000000  0.045938  \n",
       "explicit          0.016457  0.045938  1.000000  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM:  0.5\n",
      "Polynomial svm AUC:  0.521181169975\n",
      "SGD svm AUC:  0.5\n"
     ]
    }
   ],
   "source": [
    "#drop seemingly redundant features\n",
    "new_features = features.drop(['energy', 'mode', 'key', 'instrumentalness', 'explicit', 'liveness', 'valence', 'acousticness'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_features, labels, test_size=0.3, random_state= 420)  \n",
    "#standardize the data\n",
    "std = StandardScaler()  \n",
    "X_train = std.fit_transform(X_train)  \n",
    "X_test = std.transform(X_test) \n",
    "#Do LinearSVC again\n",
    "svm = LinearSVC(C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "new_preds_lin = svm.predict(X_test)\n",
    "print(\"Linear SVM: \", roc_auc_score(y_test, new_preds_lin)) #auc doesn't change from .5\n",
    "#polynomial features \n",
    "poly_feat = poly.fit_transform(features)\n",
    "X_trainP, X_testP, y_trainP, y_testP = train_test_split(poly_feat, labels, test_size=0.3, random_state= 420)  \n",
    "#redo LinearSVM\n",
    "svm_poly = LinearSVC(C=1) #kept C = 2 from LinearSVC above\n",
    "svm_poly.fit(X_trainP, y_trainP)\n",
    "poly_preds_new = svm_poly.predict(X_testP)\n",
    "print(\"Polynomial svm AUC: \",roc_auc_score(y_testP, poly_preds_new)) #polynomial performs slightly better than linear svm\n",
    "sgd_best_new = SGDClassifier(loss = 'hinge', penalty = 'l1', alpha = 0.0001, max_iter = 10000)\n",
    "sgd_best_new.fit(X_train, y_train)\n",
    "sgdPreds_new = sgd_best_new.predict(X_test)\n",
    "print(\"SGD svm AUC: \", roc_auc_score(y_test, sgdPreds_new)) #no improvement for sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only polynomial svm's AUC benefited from dropping these variables. At this point, I believe that Support Vector Machine Classifiers are not suited for our problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some LDA for fun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEKCAYAAAAW8vJGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = np.array(labels)\n",
    "lda = LDA(n_components = 3, solver = \"eigen\")  \n",
    "x_lda = lda.fit_transform(features, labels)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "clean['pc1'] = x_lda[:,0 ]\n",
    "sns.scatterplot(data=clean[['pc1', 'is_hit']] , x = \"pc1\", y = \"is_hit\", hue = \"is_hit\", style = \"is_hit\")\n",
    "plt.show()\n",
    "#source: https://medium.com/journey-2-artificial-intelligence/lda-linear-discriminant-analysis-using-python-2155cf5b6398?fbclid=IwAR2CadfG6IpRyiRYbatbCyaU0crMMZ6BgjXiTX7V0VC-62rXaneYgWiTvT8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
